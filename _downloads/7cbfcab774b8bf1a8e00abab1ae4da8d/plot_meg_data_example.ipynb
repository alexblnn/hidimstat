{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Support recovery on MEG data (2D)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport mne\nfrom mne.datasets import sample\nfrom mne.inverse_sparse.mxne_inverse import _prepare_gain, _make_sparse_stc\nfrom sklearn.cluster import FeatureAgglomeration\nfrom sklearn.cluster._agglomerative import _fix_connectivity\n\nfrom hidimstat.clustered_inference import clustered_inference\nfrom hidimstat.ensemble_clustered_inference import \\\n    ensemble_clustered_inference\nfrom hidimstat.stat_tools import zscore_from_pval\n\n\ndef preprocess_meg_eeg_data(evoked, forward, noise_cov, loose=0., depth=0.,\n                            pca=False, rank=None):\n    \"\"\"Preprocess MEG or EEG data to produce the whitened MEG/EEG measurements\n    (target) and the preprocessed gain matrix (design matrix). This function\n    is mainly wrapping the `_prepare_gain` MNE function.\n\n    Parameters\n    ----------\n    evoked : instance of mne.Evoked\n        The evoked data.\n\n    forward : instance of Forward\n        The forward solution.\n\n    noise_cov : instance of Covariance\n        The noise covariance.\n\n    loose : float in [0, 1] or 'auto'\n        Value that weights the source variances of the dipole components\n        that are parallel (tangential) to the cortical surface. If loose\n        is 0 then the solution is computed with fixed orientation.\n        If loose is 1, it corresponds to free orientations.\n        The default value ('auto') is set to 0.2 for surface-oriented source\n        space and set to 1.0 for volumic or discrete source space.\n\n    depth : None or float in [0, 1]\n        Depth weighting coefficients. If None, no depth weighting is performed.\n\n    pca : bool, optional (default=False)\n        If True, Whitener is reduced.\n        If False, Whitener is not reduced.\n\n    rank : None or int\n        Rank reduction of the whitener. If None rank is estimated from data.\n\n    Returns\n    -------\n    G : array, shape (n_channels, n_dipoles)\n        The preprocessed gain matrix.\n\n    M : array, shape (n_channels, n_times)\n        The whitened MEG/EEG measurements.\n\n    forward : instance of Forward\n        The preprocessed forward solution.\n    \"\"\"\n\n    all_ch_names = evoked.ch_names\n\n    # Handle depth weighting and whitening (here is no weights)\n    forward, G, gain_info, whitener, source_weighting, mask = \\\n        _prepare_gain(forward, evoked.info, noise_cov, pca=pca, depth=depth,\n                      loose=loose, weights=None, weights_min=None, rank=rank)\n\n    # Select channels of interest\n    sel = [all_ch_names.index(name) for name in gain_info['ch_names']]\n\n    M = evoked.data[sel]\n    M = np.dot(whitener, M)\n\n    return G, M, forward\n\n\ndef _compute_stc(zscore_active_set, active_set, evoked, forward):\n    \"\"\"Wrapper of `_make_sparse_stc`\"\"\"\n\n    X = np.atleast_2d(zscore_active_set)\n\n    if X.shape[1] > 1 and X.shape[0] == 1:\n        X = X.T\n\n    stc = _make_sparse_stc(X, active_set, forward, tmin=evoked.times[0],\n                           tstep=1. / evoked.info['sfreq'])\n    return stc\n\n\n# Downloading data\nsubject = 'sample'\ndata_path = sample.data_path()\nfwd_fname = data_path + '/MEG/sample/sample_audvis-meg-eeg-oct-6-fwd.fif'\nave_fname = data_path + '/MEG/sample/sample_audvis-ave.fif'\nraw_fname = data_path + '/MEG/sample/sample_audvis_raw.fif'\ncov_fname = data_path + '/MEG/sample/sample_audvis-shrunk-cov.fif'\nsubjects_dir = data_path + '/subjects'\ncondition = 'Left Auditory'\n\n# Read noise covariance matrix\nnoise_cov = mne.read_cov(cov_fname)\n\n# Handling average file\nevoked = mne.read_evokeds(ave_fname, condition=condition, baseline=(None, 0))\nevoked = evoked.pick_types('grad')\n# Selecting relevant time window\nevoked.plot()\nevoked.crop(tmin=0.05, tmax=0.1)\n\n# Handling forward solution:\nforward = mne.read_forward_solution(fwd_fname)\n# Collecting features' connectivity\nconnectivity = mne.source_estimate.spatial_src_adjacency(forward['src'])\n\n# Choosing frequency and number of clusters used for compression.\n# Reducing the frequency to 100Hz to make inference faster\nt_step = 0.01\nstep = int(t_step * evoked.info['sfreq'])\nevoked.decimate(step)\nt_min = evoked.times[0]\nt_step = 1. / evoked.info['sfreq']\n# Taking n_clusters > 2000 might lead to an unpowerfull inference.\n# Taking n_clusters < 500 might compress too much the data leading\n# to a compress problem not close enough to the original problem.\n# For MEG data n_clusters = 1000 is generally a good default choice.\nn_clusters = 1000\n# Setting theoretical FWER target\nfwer_target = 0.1\ncorrection_clust_inf = 1. / n_clusters\nzscore_target = zscore_from_pval((fwer_target / 2) * correction_clust_inf)\n\n\n# Preprocessing MEG data\nX, Y, forward = preprocess_meg_eeg_data(evoked, forward, noise_cov)\n\n# Initializing FeatureAgglomeration object used for the clustering step\nconnectivity_fixed, _ = \\\n    _fix_connectivity(X.T, connectivity, affinity=\"euclidean\")\nward = FeatureAgglomeration(n_clusters=n_clusters, connectivity=connectivity)\n\n# Making the inference with the clustered inference algorithm\ninference_method = 'desparsified-group-lasso'\nbeta_hat, pval, pval_corr, one_minus_pval, one_minus_pval_corr = \\\n    clustered_inference(X, Y, ward, n_clusters, method=inference_method)\n\n# Extracting active set (support)\nactive_set = np.logical_or(pval_corr < fwer_target / 2,\n                           one_minus_pval_corr < fwer_target / 2)\nactive_set_full = np.copy(active_set)\nactive_set_full[:] = True\n\n# Computing z-scores\nzscore = zscore_from_pval(pval, one_minus_pval)\nzscore_active_set = zscore[active_set]\n\n# Building mne.SourceEstimate object\nstc = _compute_stc(zscore_active_set, active_set, evoked, forward)\n\n# Plotting\nmne.viz.set_3d_backend(\"pyvista\")\nmax_stc = np.max(np.abs(stc._data))\nclim = dict(pos_lims=(3, zscore_target, max_stc), kind='value')\nbrain = stc.plot(subject=subject, hemi='lh', clim=clim,\n                 subjects_dir=subjects_dir)\nbrain.show_view('lat')\nbrain.add_text(0.05, 0.9, 'audio - cd-MTLasso (AR1)', 'title', font_size=30)\nbrain.save_image('figures/meg_audio_cd-MTLasso.png')\n\ninteractive_plot = False\nif interactive_plot:\n    brain = stc.plot(subject=subject, hemi='both',\n                     subjects_dir=subjects_dir, clim=clim)\n\n# Runing the ensmeble clustered inference algorithm on temporal data\n# might take several minutes on standard device with `n_jobs=1` (around 10 mn)\nrun_ensemble_clustered_inference = False\nif run_ensemble_clustered_inference:\n\n    # Making the inference with the ensembled clustered inference algorithm\n    beta_hat, pval, pval_corr, one_minus_pval, one_minus_pval_corr = \\\n        ensemble_clustered_inference(X, Y, ward, n_clusters,\n                                     inference_method=inference_method)\n\n    # Extracting active set (support)\n    active_set = np.logical_or(pval_corr < fwer_target / 2,\n                               one_minus_pval_corr < fwer_target / 2)\n    active_set_full = np.copy(active_set)\n    active_set_full[:] = True\n\n    # Computing z-scores\n    zscore = zscore_from_pval(pval, one_minus_pval)\n    zscore_active_set = zscore[active_set]\n\n    # Building mne.SourceEstimate object\n    stc = _compute_stc(zscore_active_set, active_set, evoked, forward)\n\n    # Plotting\n    mne.viz.set_3d_backend(\"pyvista\")\n    max_stc = np.max(np.abs(stc._data))\n    clim = dict(pos_lims=(3, zscore_target, max_stc), kind='value')\n    brain = stc.plot(subject=subject, hemi='lh', clim=clim,\n                     subjects_dir=subjects_dir)\n    brain.show_view('lat')\n    brain.add_text(0.05, 0.9, 'audio - ecd-MTLasso (AR1)',\n                   'title', font_size=30)\n\n    interactive_plot = False\n    if interactive_plot:\n        brain = stc.plot(subject=subject, hemi='both',\n                         subjects_dir=subjects_dir, clim=clim)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}